Task: Please describe how you would handle reading/parsing very large datasets (10s of GiB) in Python?

Answer:
On very large datasets it is better to use batchs of data. Each batch can then
be processed/parsed independently without running out of memory. With enough ressources at hand,
we could also run the batches in parallel through multi-threading or distribution across 
different systems to optimize computing time. 
...
